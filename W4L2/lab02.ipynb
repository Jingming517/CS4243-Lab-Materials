{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 02 - Zoom and Filters\n",
    "References: https://docs.opencv.org/4.6.0/index.html\n",
    "\n",
    "Prepared by Li Jiahe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an example image\n",
    "img = cv2.imread(\"images/cat_bw.bmp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zoom-in, Zoom-out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To scale an image, we use `cv2.resize(img, dsize, fx, fy, interpolation)`\n",
    "* `img`: source image\n",
    "* `dsize`: target size in form (`width`, `height`) or (`x`, `y`)\n",
    "* `fx`: resize factor for _x_-axis (width)\n",
    "* `fy`: resize factor for _y_-axis (height)\n",
    "* `interpolation`: interpolation methods. We will cover some common ones here. The full list of interpolation flags can be found [here](https://docs.opencv.org/4.x/da/d54/group__imgproc__transform.html#ga5bb5a1fea74ea38e1a5445ca803ff121)\n",
    "    - `INTER_NEAREST` – a nearest‐neighbor interpolation\n",
    "    - `INTER_LINEAR` – a bilinear interpolation (used by default)\n",
    "    - `INTER_AREA` – resampling using pixel area relation. It may be a preferred method for image decimation, as it gives moire’‐free results. But when the image is zoomed, it is similar to the INTER_NEAREST method.\n",
    "    - `INTER_CUBIC` – a bicubic interpolation over 4×4 pixel neighborhood\n",
    "    - `INTER_LANCZOS4` – a Lanczos interpolation over 8×8 pixel neighborhood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow(\"Original\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shrink Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simg_area = cv2.resize(img, None, fx=0.25, fy=0.25, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "cv2.imshow(\"Shrink\", simg_area)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simg_area.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison between Different Interpolation Methods for Shrinking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simg_near = cv2.resize(img, None, fx=0.25, fy=0.25, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "simg_lin = cv2.resize(img, None, fx=0.25, fy=0.25, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "simg_cub = cv2.resize(img, None, fx=0.25, fy=0.25, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "simg_lanc = cv2.resize(img, None, fx=0.25, fy=0.25, interpolation=cv2.INTER_LANCZOS4)\n",
    "\n",
    "simg_comp = np.concatenate((simg_area, simg_near), axis=1)\n",
    "cv2.imshow(\"Compare Shrink\", simg_comp)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enlarge Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limg_area = cv2.resize(img, None, fx=4, fy=4, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "cv2.imshow(\"Enlarge\", limg_area)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison between Different Interpolation Methods for Enlarging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limg_near = cv2.resize(img, None, fx=4, fy=4, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "limg_lin = cv2.resize(img, None, fx=4, fy=4, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "limg_cub = cv2.resize(img, None, fx=4, fy=4, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "limg_lanc = cv2.resize(img, None, fx=4, fy=4, interpolation=cv2.INTER_LANCZOS4)\n",
    "\n",
    "limg_comp = np.concatenate((limg_near, limg_cub), axis=1)\n",
    "cv2.imshow(\"Compare Enlarge\", limg_comp)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial Domain Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in one-dimensional signals, images also can be filtered with various low-pass filters (LPF), high-pass filters (HPF), etc. LPF helps in removing noise, blurring images, etc. HPF filters help in finding edges in images.\n",
    "\n",
    "Reference: https://docs.opencv.org/3.4/d4/d13/tutorial_py_filtering.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori_img = cv2.imread(\"images/carpixel-1976-ferrari-512-bb-.jpg\")\n",
    "noisy_img = cv2.imread(\"images/noisy_carpixel-1976-ferrari-512-bb-snp_nc20.jpg\")\n",
    "\n",
    "cv2.imshow(\"Noisy\", noisy_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D Convolutional Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `cv2.filter2D(src, ddepth, kernel, anchor, delta, borderType)`\n",
    "* `src` input image.\n",
    "* `ddepth` desired depth of the destination image, see [combinations](https://docs.opencv.org/3.4/d4/d86/group__imgproc__filter.html#filter_depths)\n",
    "* `kernel` convolution kernel (or rather a correlation kernel), a single-channel floating point matrix; if you want to apply different kernels to different channels, split the image into separate color planes using split and process them individually.\n",
    "* `anchor` anchor of the kernel that indicates the relative position of a filtered point within the kernel; the anchor should lie within the kernel; default value (-1,-1) means that the anchor is at the kernel center.\n",
    "* `delta` optional value added to the filtered pixels before storing them in dst.\n",
    "* `borderType` pixel extrapolation method, see [BorderTypes](https://docs.opencv.org/3.4/d2/de8/group__core__array.html#ga209f2f4869e304c82d07739337eae7c5). BORDER_WRAP is not supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hl2 = np.array([[1/9, 1/9, 1/9], [1/9, 1/9, 1/9], [1/9, 1/9, 1/9]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hl2_nimg = cv2.filter2D(src=noisy_img, ddepth=-1, kernel=hl2)\n",
    "\n",
    "cv2.imshow(\"hl2\", hl2_nimg)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Smoothing Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Averaging Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average filter in cv2 is `cv2.blur(src, ksize, anchor)`\n",
    "* `src` input image; it can have any number of channels, which are processed independently, but the depth should be CV_8U, CV_16U, CV_16S, CV_32F or CV_64F.\n",
    "* `ksize` blurring kernel size.\n",
    "* `anchor` anchor of the kernel that indicates the relative position of a filtered point within the kernel; the anchor should lie within the kernel; default value (-1,-1) means that the anchor is at the kernel center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_nimg = cv2.blur(noisy_img, (5, 5))\n",
    "\n",
    "cv2.imshow(\"Average\", avg_nimg)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Median Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The median filter in cv2 is `cv2.medianBlur(src, ksize)`\n",
    "* `src` input 1-, 3-, or 4-channel image; when ksize is 3 or 5, the image depth should be CV_8U, CV_16U, or CV_32F, for larger aperture sizes, it can only be CV_8U.\n",
    "* `ksize` perture linear size; it must be odd and greater than 1, for example: 3, 5, 7 ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_nimg = cv2.medianBlur(noisy_img, 5)\n",
    "\n",
    "cv2.imshow(\"Median\", median_nimg)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Gaussian Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Gaussian filter in cv2 is `cv2.GaussianBlur(src, ksize, sigmaX, sigmaY)`\n",
    "* `src` input image; the image can have any number of channels, which are processed independently, but the depth should be CV_8U, CV_16U, CV_16S, CV_32F or CV_64F.\n",
    "* `ksize` Gaussian kernel size. ksize.width and ksize.height can differ but they both must be positive and odd. Or, they can be zero's and then they are computed from sigma.\n",
    "* `sigmaX` Gaussian kernel standard deviation in X direction.\n",
    "* `sigmaY` Gaussian kernel standard deviation in Y direction; if sigmaY is zero, it is set to be equal to sigmaX, if both sigmas are zeros, they are computed from ksize.width and ksize.height, respectively (see getGaussianKernel for details); to fully control the result regardless of possible future modifications of all this semantics, it is recommended to specify all of ksize, sigmaX, and sigmaY.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gauss_nimg = cv2.GaussianBlur(noisy_img, (5, 5), 0)\n",
    "\n",
    "cv2.imshow(\"Gaussian\", gauss_nimg)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge Detection Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_img = cv2.cvtColor(ori_img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hh4 = np.array([[0, -1, 0], [-1, 4, -1], [0, -1, 0]]) \n",
    "\n",
    "hh4_img = cv2.filter2D(src=gray_img, ddepth=-1, kernel=hh4)\n",
    "\n",
    "cv2.imshow(\"hh2\", hh4_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Laplacian Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Laplacian filter in cv2 is `cv2.Laplacian(src, ddepth, ksize=1, scale=1, delta=0)`\n",
    "* `src`\tSource image.\n",
    "* `ddepth` Desired depth of the destination image, see [combinations](https://docs.opencv.org/3.4/d4/d86/group__imgproc__filter.html#filter_depths).\n",
    "* `ksize` Aperture size used to compute the second-derivative filters. See [getDerivKernels](https://docs.opencv.org/3.4/d4/d86/group__imgproc__filter.html#ga6d6c23f7bd3f5836c31cfae994fc4aea) for details. The size must be positive and odd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lap_img = cv2.Laplacian(gray_img, -1, ksize=5)\n",
    "\n",
    "cv2.imshow(\"Laplacian\", lap_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Sobel Operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Sobel Filter in cv2 is `cv.Sobel(src, ddepth, dx, dy, ksize=3)`\n",
    "* `src` input image.\n",
    "* `ddepth` output image depth, see see [combinations](https://docs.opencv.org/3.4/d4/d86/group__imgproc__filter.html#filter_depths).\n",
    "* `dx` order of the derivative x.\n",
    "* `dy` order of the derivative y.\n",
    "* `ksize` size of the extended Sobel kernel; it must be 1, 3, 5, or 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sobel_img_x = cv2.Sobel(gray_img, -1, dx=1, dy=0, ksize=5)\n",
    "sobel_img_y = cv2.Sobel(gray_img, -1, dx=0, dy=1, ksize=5)\n",
    "sobel_img_xy = cv2.Sobel(gray_img, -1, dx=1, dy=1, ksize=5)\n",
    "\n",
    "compare_xy = np.concatenate((sobel_img_x, sobel_img_y), axis=1)\n",
    "\n",
    "cv2.imshow(\"Compare XY\", compare_xy)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "\n",
    "cv2.imshow(\"Sobel XY\", sobel_img_xy)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
